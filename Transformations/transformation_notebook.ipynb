{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a6ef6e9-6eb2-4970-8ca3-438cb6b6b492",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a catalog"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create a catalog (if it doesn't already exist)\n",
    "CREATE CATALOG IF NOT EXISTS catalog_for_sales;\n",
    "\n",
    "-- Use the catalog\n",
    "USE CATALOG catalog_for_sales;\n",
    "\n",
    "-- Create schemas (if they don't exist)\n",
    "CREATE SCHEMA IF NOT EXISTS bronze_schema;\n",
    "CREATE SCHEMA IF NOT EXISTS silver_schema;\n",
    "CREATE SCHEMA IF NOT EXISTS gold_schema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ea68466-d422-440b-a6ff-f9d5533941d1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import all the required libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField,StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import to_date, lit, concat, col, lpad,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64161722-22e6-42e5-8561-76f3b683d0fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read the data from adls"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('parquet')\\\n",
    "      .options(inferSchema=True)\\\n",
    "        .load('abfss://bronze@projectandstorage.dfs.core.windows.net/rawdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8058eb28-33a7-4124-a80d-81568b0334b8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check the schema"
    }
   },
   "outputs": [],
   "source": [
    "# show the table\n",
    "df.show(5)\n",
    "# check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5780a4b7-f89f-467b-8ea1-c92bb179c3a2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Redefine the schema of table"
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Revenue\",col(\"Revenue\").cast(DoubleType()))\\\n",
    "    .withColumn(\"Units_Sold\",col(\"Units_Sold\").cast(IntegerType()))\\\n",
    "    .withColumn(\"Day\",col(\"Day\").cast(IntegerType()))\\\n",
    "    .withColumn(\"Month\",col(\"Month\").cast(IntegerType()))\\\n",
    "    .withColumn(\"Year\",col(\"Year\").cast(IntegerType()))\\\n",
    "\n",
    "# check the Schema\n",
    "df.printSchema()\n",
    "\n",
    "# show the table\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92161399-3c53-4d0b-9450-9b7e872bfdca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check the duplicates and drop if exists"
    }
   },
   "outputs": [],
   "source": [
    "duplicates = df.groupBy(df.columns).count().filter(\"count>1\")\n",
    "if duplicates.count()>0:\n",
    "    print(\"Duplicates found:\")\n",
    "    duplicates.show()\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "\n",
    "# Drop duplicates\n",
    "df= df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73fbc754-4664-4fdb-afdb-8686499de272",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Drop Null values greater than 50%"
    }
   },
   "outputs": [],
   "source": [
    "null_counts= df.select([col(c).isNull().alias(c) for c in df.columns])\n",
    "for column in null_counts.columns:\n",
    "    null_count= null_counts.filter(col(column)).count()\n",
    "    if null_count > 0:\n",
    "        print(f\"Null values found in column {column}: {null_count}\")\n",
    "\n",
    "# Define the threshold for dropping rows (50% null values)\n",
    "threshold = int(len(df.columns) * 0.5)\n",
    "\n",
    "# Count the number of nulls per row and drop rows with null count above the threshold\n",
    "df = df.withColumn(\"null_count\", sum(col(c).isNull().cast(\"int\") for c in df.columns)) \\\n",
    "               .filter(col(\"null_count\") <= threshold) \\\n",
    "               .drop(\"null_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d40a01-dda4-423e-b7ba-3cf4ae3d93fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "add the required columns"
    }
   },
   "outputs": [],
   "source": [
    "# create Date column\n",
    "df = df.withColumn(\"Date\",to_date(concat(col(\"Year\"), lit(\"-\"), lpad(col(\"Month\"), 2, \"0\"),lit(\"-\"),lpad(col(\"Day\"), 2, \"0\")), \"yyyy-MM-dd\"))\n",
    "\n",
    "# create model_category\n",
    "df = df.withColumn(\"Model_Category\",split(col(\"Model_ID\"),\"-\")[0])\n",
    "\n",
    "# Calculate the Revenue per Unit column\n",
    "df = df.withColumn(\"RevperUnit\",col(\"Revenue\")/col(\"Units_Sold\"))\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9d988a-7003-484e-b588-2c5b5078301a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data writting into silver_layer\n",
    "df.write.format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"path\",\"abfss://silver@projectandstorage.dfs.core.windows.net/carsales\")\\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4692820071624641,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "transformation_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
